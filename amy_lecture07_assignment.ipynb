{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56dbc19b-0f79-45de-8606-acbd0723d33b",
   "metadata": {},
   "source": [
    "# Lecture07 assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfca1d8-059d-4d60-9db1-4e5937a169bf",
   "metadata": {},
   "source": [
    "#### 1. Print Specific Files from a Zip Archive\n",
    "Question: Write a Python script to collect only **.fna.gz** files that do not contain the substring cds from a zip archive named **assignment_data.zip**. The script should collect the file names and their uncompressed sizes in bytes in the **output list**. (5 points)\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use ZipFile to iterate over files in the archive and filter them based on the specified conditions.\n",
    "- Use the ZipInfo.<span style=\"color:#3d85c6\">file_size</span> attribute to get the uncompressed size of each selected file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a09ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code without Path\n",
    "# import re\n",
    "# from zipfile import ZipFile as zf\n",
    "\n",
    "# output = []\n",
    "# with zf(\"assignment_data.zip\", \"r\") as inZF:\n",
    "#     all_file_list = inZF.infolist()\n",
    "#     all_file_list_cleanned = []\n",
    "#     # remove folder from all_file_list\n",
    "#     for file in all_file_list:\n",
    "#         if file.is_dir() == False:\n",
    "#             all_file_list_cleanned.append(file)\n",
    "#     # print([x for x in all_file_list if x not in all_file_list_cleanned])\n",
    "\n",
    "#     # filter using re pattern\n",
    "#     # output is list of tuple [(,), (,)]\n",
    "\n",
    "#     pattern = r\"GCF_\\w+.\\w+_genomic\\.fna\\.gz\"\n",
    "#     for file in all_file_list_cleanned:\n",
    "#         matches = re.search(pattern, file.filename)\n",
    "#         if matches:\n",
    "#             # print(matches[0], file.file_size)\n",
    "#             output.append((matches[0],file.file_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c604e50e-4a5c-4fd9-8367-c0b82ae2924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "from zipfile import ZipFile as zf\n",
    "from pathlib import Path\n",
    "\n",
    "output = []\n",
    "with zf(\"assignment_data.zip\", \"r\") as inZF:\n",
    "    all_file_list = inZF.infolist()\n",
    "    \n",
    "    for file in all_file_list:\n",
    "       if '.fna.gz' in file.filename and not 'cds' in file.filename:\n",
    "           fname = Path(file.filename)\n",
    "           output.append((fname.name, file.file_size))\n",
    "           #print(fname.name, file.file_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1770c0a8-0eb7-4de3-8d5f-2ee2b1aa8325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_000091345.1_ASM9134v1_genomic.fna.gz, file size: 475447 bytes\n",
      "GCF_000013245.1_ASM1324v1_genomic.fna.gz, file size: 483245 bytes\n",
      "GCF_000011725.1_ASM1172v1_genomic.fna.gz, file size: 478748 bytes\n",
      "GCF_000093185.1_ASM9318v1_genomic.fna.gz, file size: 480190 bytes\n",
      "GCF_000021165.1_ASM2116v1_genomic.fna.gz, file size: 500790 bytes\n",
      "GCF_000008785.1_ASM878v1_genomic.fna.gz, file size: 495396 bytes\n",
      "GCF_000023805.1_ASM2380v1_genomic.fna.gz, file size: 472639 bytes\n",
      "GCF_000020245.1_ASM2024v1_genomic.fna.gz, file size: 483848 bytes\n",
      "GCF_000008525.1_ASM852v1_genomic.fna.gz, file size: 502194 bytes\n"
     ]
    }
   ],
   "source": [
    "## Expected output\n",
    "for fname, fsize in output:\n",
    "    print(f\"{fname}, file size: {fsize} bytes\") ## print result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772e8a5-b2f5-4f24-90ee-ec36e886d67b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ba5c1-1879-4335-8637-9c70dd68a7af",
   "metadata": {},
   "source": [
    "#### 2. Convert Date String to Datetime\n",
    "Question: Write a Python script that converts a string representing a date and time (**\"2024-08-26 14:30:00\"**) into a datetime object. Then, print the formatted string **'Mon Aug 26 14:30:00 2024'** using the strftime method. (2 points)\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use the <span style=\"color:green\">**datetime.strptime()**</span> method to parse the date string.\n",
    "- Use the <span style=\"color:green\">**strftime()**</span> method to format the datetime object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a96ea5de-2594-4824-8e0f-daf6b9da4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date_str = \"2024-08-26 14:30:00\"\n",
    "## get datetime obj.\n",
    "date_object = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "#print(date_object)\n",
    "date_out = date_object.strftime(\"%a %b %d %H:%M:%S %Y\")\n",
    "## create output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e056c53-9d2b-4e07-ae08-ce4d46918d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 26 14:30:00 2024\n"
     ]
    }
   ],
   "source": [
    "print(date_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac77709-8e52-4913-a3f0-3bf2ac4bb574",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716425a-960c-439f-b4f4-9ef3f455c6d4",
   "metadata": {},
   "source": [
    "#### 3. Measure Script Execution Time\n",
    "Question: Write a Python script that measures and compares the execution time of two loops:\n",
    "\n",
    "- A loop that iterates directly over a <span style=\"color:green\">**range**</span> of numbers from 0 to 100,000,000.\n",
    "- A loop that iterates over a <span style=\"color:green\">**list**</span> created from the same range of numbers.\n",
    "  \n",
    "Your task is to measure and print the execution time of both loops to determine the difference in performance between iterating over a range object and iterating over a list created from that range. (2 points)\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use the <span style=\"color:green\">**time.time()**</span> function to capture the start and end times for both loops.\n",
    "- Consider the memory and computational differences between using a <span style=\"color:green\">**range**</span> and a <span style=\"color:green\">**list**</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "23ac29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time (range): 1.7435460090637207 seconds\n",
      "Execution Time (list): 3.7202017307281494 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# Measure the time it takes to loop over a range of 100,000,000 numbers\n",
    "start_time = time.time()\n",
    "for i in range(100000000):\n",
    "    pass\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time (range): {end_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "# Measure the time it takes to create a list from a range of 100,000,000 numbers and loop over it\n",
    "start_time = time.time()\n",
    "for i in list(range(100000000)):\n",
    "    pass\n",
    "end_time = time.time()\n",
    "print(f\"Execution Time (list): {end_time - start_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674bc2a-6b5f-48d8-917a-f0cf7ba6572d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dca701-a59f-439e-965c-4b227d2b1d95",
   "metadata": {},
   "source": [
    "#### 4. Persistent Data Storage with pickle\n",
    "Question: Write a Python script that serializes a list of dictionaries containing student names and their grades into a file named **students.pkl** using the pickle module. Then, write another script to deserialize the data and print it. (1 point)\n",
    "\n",
    "Hints:\n",
    "\n",
    "- Use <span style=\"color:green\">**pickle.dump()**</span> to serialize the data.\n",
    "- Use <span style=\"color:green\">**pickle.load()**</span> to deserialize the data.\n",
    "  \n",
    "**Expected Outcome:** The script should store the list of dictionaries in **students.pkl** and then load and print the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b0c45d11-15bb-479e-9dc1-91ae9ca724a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# List of dictionaries to serialize\n",
    "students = [\n",
    "    {'name': 'John', 'grade': 'A'},\n",
    "    {'name': 'Jane', 'grade': 'B'},\n",
    "    {'name': 'Doe', 'grade': 'C'}\n",
    "]\n",
    "\n",
    "# Serialize the list to a file\n",
    "with open('students.pkl', 'wb') as outputfile:\n",
    "    pickle.dump(students, outputfile)\n",
    "\n",
    "# Deserialize the list from the file\n",
    "with open('students.pkl', 'rb') as infile:\n",
    "    loaded_students = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8a5b6b05-ab97-42d4-80e5-077adb8e8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'John', 'grade': 'A'}, {'name': 'Jane', 'grade': 'B'}, {'name': 'Doe', 'grade': 'C'}]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609fbba6-2051-4914-97f6-8ff79bb133a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11a6eb-5cf9-4467-8915-9bca0d53efa5",
   "metadata": {},
   "source": [
    "#### 5. Extracting and Processing JSONL Files from a Zip Archive to Generate a TSV Report\n",
    "Question: Please complete a Python code below and reproduce the following Output. You need to upload \"data_table.tsv\" and the completed Python code below. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b348ad8c-6dee-40f0-a855-23441a572947",
   "metadata": {},
   "source": [
    "### Please complete the Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dccc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "import re, csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "## Extract only file with .jsonl from assignment_data.zip\n",
    "jsonl_list = []\n",
    "pattern = r'.*\\.jsonl'\n",
    "data_info = {\n",
    "                'assembly_id' : [],\n",
    "                'genbank_id' : [],\n",
    "                'moleculeType' : [],\n",
    "                'length' : []\n",
    "            }\n",
    "\n",
    "with ZipFile('assignment_data.zip') as zipf:\n",
    "    ## loop over file in ZipFile\n",
    "    files = zipf.infolist()\n",
    "    #print(files)\n",
    "    for f in files:\n",
    "        #print(f.filename)\n",
    "        matches = re.search(pattern, f.filename)\n",
    "        if matches:\n",
    "            #print(matches[0])\n",
    "            jsonl_list.append(matches[0])\n",
    "            zipf.extract(matches[0])\n",
    "#print(jsonl_list)\n",
    "paths = Path('./assignment_data/data/')\n",
    "with open('data_table.tsv','w', newline='') as csvOut:\n",
    "    writer = csv.writer(csvOut, delimiter=\"\\t\")## create writer object\n",
    "    writer.writerow(['assembly_id', 'genbank_id', 'moleculeType', 'length']) ## write header\n",
    "    ## read file.jsonl\n",
    "    for file_path in jsonl_list:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                data_info['assembly_id'].append(data['assemblyUnit'])\n",
    "                data_info['genbank_id'].append(data['genbankAccession'])\n",
    "                data_info['moleculeType'].append(data['assignedMoleculeLocationType'])\n",
    "                data_info['length'].append(data['length'])\n",
    "\n",
    "                df = pd.DataFrame(data_info)\n",
    "    \n",
    "    for index, row in df.iterrows(): ## write the information from jsonl to tsv file\n",
    "        writer.writerow([row['assembly_id'], row['genbank_id'], row['moleculeType'], row['length']])\n",
    "\n",
    "#print(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbcb7c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assembly_id\tgenbank_id\tmoleculeType\tlength\n",
      "GCF_000091355.1\tFM991728.1\tChromosome\t1576758\n",
      "GCF_000013255.1\tCP000241.1\tChromosome\t1596366\n",
      "GCF_000013255.1\tCP000242.1\tPlasmid\t9370\n",
      "GCF_000011735.1\tCP000012.1\tChromosome\t1589954\n",
      "GCF_000093195.1\tCP001582.1\tChromosome\t1588278\n",
      "GCF_000093195.1\tCP001583.1\tPlasmid\t7326\n",
      "GCF_000021175.1\tCP001173.1\tChromosome\t1652982\n",
      "GCF_000021175.1\tCP001174.1\tPlasmid\t10031\n",
      "GCF_000008795.1\tAE001439.1\tChromosome\t1643831\n",
      "GCF_000023815.1\tCP001680.1\tChromosome\t1568826\n",
      "GCF_000020255.1\tCP001072.2\tChromosome\t1608548\n",
      "GCF_000008535.1\tAE000511.1\tChromosome\t1667867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#without pandas\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "import re, csv\n",
    "import csv\n",
    "\n",
    "jsonl_list = []\n",
    "\n",
    "with ZipFile('assignment_data.zip') as zipf:\n",
    "    ## loop over file in ZipFile\n",
    "    files = zipf.infolist()\n",
    "    #print(files)\n",
    "    for f in files:\n",
    "        #print(f.filename)\n",
    "        matches = re.search(pattern, f.filename)\n",
    "        if matches:\n",
    "            #print(matches[0])\n",
    "            jsonl_list.append(matches[0])\n",
    "            zipf.extract(matches[0])\n",
    "#print(jsonl_list)\n",
    "paths = Path('./assignment_data/data/')\n",
    "with open('data_tabl.tsv','w',\n",
    "           newline='') as csvOut:\n",
    "    writer = csv.writer(csvOut, delimiter=\"\\t\")## create writer object\n",
    "    writer.writerow(['assembly_id', 'genbank_id', 'moleculeType', 'length']) ## write header\n",
    "\n",
    "data_info_list =[]\n",
    "for i in range(len(data_info['assembly_id'])):\n",
    "    record = [data_info['assembly_id'][i], data_info['genbank_id'][i], data_info['moleculeType'][i], data_info['length'][i]]\n",
    "    data_info_list.append(record)\n",
    "\n",
    "with open('data_tabl.tsv', 'a', newline='') as f: \n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerows(data_info_list)\n",
    "\n",
    "print( Path('data_tabl.tsv').read_text() )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296d45b-bba2-4b91-9231-b08f04dfac5a",
   "metadata": {},
   "source": [
    "### Output from your python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bbe77100-7920-43ff-bdb9-0244da7260b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment_data\\data\\GCF_000008525.1\n",
      "assignment_data\\data\\GCF_000008785.1\n",
      "assignment_data\\data\\GCF_000011725.1\n",
      "assignment_data\\data\\GCF_000013245.1\n",
      "assignment_data\\data\\GCF_000020245.1\n",
      "assignment_data\\data\\GCF_000021165.1\n",
      "assignment_data\\data\\GCF_000023805.1\n",
      "assignment_data\\data\\GCF_000091345.1\n",
      "assignment_data\\data\\GCF_000093185.1\n",
      "assignment_data\\data\\GCF_000008525.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000008785.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000011725.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000013245.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000020245.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000021165.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000023805.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000091345.1\\sequence_report.jsonl\n",
      "assignment_data\\data\\GCF_000093185.1\\sequence_report.jsonl\n"
     ]
    }
   ],
   "source": [
    "for l in paths.rglob(\"*.*\"): #files that have extensions\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9296097c-ba12-4730-afa0-08934fafef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assembly_id\tgenbank_id\tmoleculeType\tlength\n",
      "GCF_000091355.1\tFM991728.1\tChromosome\t1576758\n",
      "GCF_000013255.1\tCP000241.1\tChromosome\t1596366\n",
      "GCF_000013255.1\tCP000242.1\tPlasmid\t9370\n",
      "GCF_000011735.1\tCP000012.1\tChromosome\t1589954\n",
      "GCF_000093195.1\tCP001582.1\tChromosome\t1588278\n",
      "GCF_000093195.1\tCP001583.1\tPlasmid\t7326\n",
      "GCF_000021175.1\tCP001173.1\tChromosome\t1652982\n",
      "GCF_000021175.1\tCP001174.1\tPlasmid\t10031\n",
      "GCF_000008795.1\tAE001439.1\tChromosome\t1643831\n",
      "GCF_000023815.1\tCP001680.1\tChromosome\t1568826\n",
      "GCF_000020255.1\tCP001072.2\tChromosome\t1608548\n",
      "GCF_000008535.1\tAE000511.1\tChromosome\t1667867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( Path('data_table.tsv').read_text() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
